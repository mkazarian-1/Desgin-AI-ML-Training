{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T11:24:04.553953Z",
     "start_time": "2025-04-28T11:24:04.379041Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install roboflow",
   "id": "39b1aea412a70642",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "/bin/bash: line 1: pip: command not found\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-28T11:56:36.184895Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "GPU 0 memory: 8.59 GB\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "\n",
      "Dataset Information:\n",
      "Classes: ['Bed', 'Chair', 'Cupboard', 'Nightstand', 'Sideboard', 'Sofa', 'Table']\n",
      "Number of classes: 7\n",
      "Train images: 0\n",
      "Validation images: 0\n",
      "Test images: 0\n",
      "\n",
      "Initializing YOLOv8s model...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:01<00:00, 11.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Ultralytics 8.3.119 ðŸš€ Python-3.12.9 torch-2.7.0+cu126 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov8s.pt, data=/mnt/e/IT/AI/JupyterProject/furniture-detection-1/data.yaml, epochs=50, time=None, patience=15, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=4, project=furniture_detection, name=yolov8s_furniture, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, cutmix=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=furniture_detection/yolov8s_furniture\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/home/wsluser/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 4.90MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2118757  ultralytics.nn.modules.head.Detect           [7, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,138,309 parameters, 11,138,293 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:01<00:00, 4.89MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed âœ…\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mFast image access âœ… (ping: 1.6Â±0.0 ms, read: 22.2Â±10.9 MB/s, size: 60.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /mnt/e/IT/AI/JupyterProject/furniture-detection-1/train/labels... 14307 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14307/14307 [00:22<00:00, 628.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: /mnt/e/IT/AI/JupyterProject/furniture-detection-1/train/labels.cache\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 2603, len(boxes) = 16363. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access âœ… (ping: 1.7Â±0.1 ms, read: 11.2Â±8.8 MB/s, size: 32.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /mnt/e/IT/AI/JupyterProject/furniture-detection-1/valid/labels... 652 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 652/652 [00:01<00:00, 536.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: /mnt/e/IT/AI/JupyterProject/furniture-detection-1/valid/labels.cache\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 63, len(boxes) = 711. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "Plotting labels to furniture_detection/yolov8s_furniture/labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001B[1mfurniture_detection/yolov8s_furniture\u001B[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      3.76G     0.9156      1.654      1.447          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:57<00:00,  5.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.703      0.661      0.709      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      3.53G     0.8448       1.08      1.369         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:52<00:00,  5.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.705      0.682      0.735      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      3.54G     0.9083      1.148      1.415         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:46<00:00,  5.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.569      0.562      0.566       0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      3.55G     0.9427      1.213      1.437         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:46<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.658      0.645      0.681      0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      3.65G     0.9001      1.117      1.403          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:48<00:00,  5.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711       0.82      0.747      0.836      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      3.52G     0.8584       1.04      1.371          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:44<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.801      0.769      0.825      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      3.52G     0.8323     0.9822       1.35         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:43<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.848      0.783      0.877      0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      3.53G     0.8098     0.9253      1.332          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:45<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.852      0.799       0.88       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      3.64G     0.7807      0.893      1.309          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:47<00:00,  5.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.863      0.822      0.889      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      3.54G     0.7502     0.8486      1.288          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:44<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.833      0.809      0.869      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      3.52G      0.743     0.8174      1.281         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:48<00:00,  5.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.879      0.797      0.908      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      3.54G     0.7229     0.7918       1.27          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:46<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.881      0.819      0.901      0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      3.65G     0.7216     0.7794      1.269          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:44<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.869      0.843      0.907      0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      3.53G     0.7076     0.7495      1.254          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:45<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.847      0.846      0.908      0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      3.51G     0.6913     0.7269      1.242         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:45<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.876      0.849       0.91      0.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      3.55G     0.6754      0.701      1.235          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:43<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.885      0.849      0.915      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      3.65G     0.6685     0.6875      1.227          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:46<00:00,  5.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.895      0.873      0.925      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      3.52G     0.6594     0.6741       1.22          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:43<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.896      0.881       0.93      0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      3.52G     0.6572      0.659      1.218          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:45<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.906      0.864      0.927      0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      3.54G     0.6439     0.6456      1.208          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:47<00:00,  5.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.906      0.879      0.935      0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      3.79G      0.632     0.6312      1.198          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:44<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.854      0.857      0.915      0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      3.53G     0.6197      0.607      1.194         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:44<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.908      0.875      0.929      0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      3.52G     0.6236     0.6042      1.195         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:51<00:00,  5.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.903      0.876      0.929      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      3.56G     0.6078     0.5976      1.182         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:51<00:00,  5.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.911      0.879      0.929      0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      3.79G     0.6027     0.5773      1.177         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [03:02<00:00,  4.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.895      0.869      0.935       0.76\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      3.54G     0.5947     0.5668      1.173         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:52<00:00,  5.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.896      0.878      0.935      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      3.51G     0.5882     0.5572      1.171          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:51<00:00,  5.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.904      0.866       0.93      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      3.54G     0.5773     0.5422      1.161          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:58<00:00,  5.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.909      0.863      0.934      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      3.67G     0.5766     0.5422      1.162         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:52<00:00,  5.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:08<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.932      0.867      0.945      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      3.53G     0.5655     0.5306      1.152          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [04:11<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.907      0.884      0.939       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      3.51G     0.5639      0.519      1.149         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [04:15<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.898      0.903      0.939      0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      3.55G     0.5549     0.5083      1.146          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [04:19<00:00,  3.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:08<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.912      0.894       0.94      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50       3.5G     0.5466      0.504      1.138          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [04:16<00:00,  3.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.922      0.882      0.947      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      3.53G      0.541     0.4959      1.135          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [04:20<00:00,  3.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:08<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.933      0.882       0.94      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      3.52G     0.5355      0.483      1.133         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [04:12<00:00,  3.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.923       0.88      0.945      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      3.54G     0.5255     0.4762      1.125         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [03:02<00:00,  4.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711       0.92        0.9      0.947       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      3.51G     0.5196     0.4661      1.121          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [03:28<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:08<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.905      0.897      0.943      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      3.53G     0.5183     0.4612      1.119         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [03:37<00:00,  4.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.909      0.879      0.944      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      3.51G     0.5079     0.4508      1.114          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [03:38<00:00,  4.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:08<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.911      0.889      0.944      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      3.55G     0.5026     0.4453      1.109          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [03:22<00:00,  4.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.901       0.89      0.942      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      3.79G     0.4321     0.3103      1.127          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:50<00:00,  5.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.911      0.891      0.939      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      3.53G     0.4101     0.2863      1.104          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:49<00:00,  5.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.919      0.863      0.934      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      3.52G     0.3964     0.2741       1.09          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:52<00:00,  5.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.927      0.882      0.933      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      3.54G     0.3839     0.2615      1.083          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:51<00:00,  5.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.911      0.889      0.936      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50       3.5G     0.3783     0.2535      1.074          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:53<00:00,  5.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.904      0.891      0.931      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      3.53G     0.3643     0.2439      1.063          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:49<00:00,  5.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:06<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.918      0.861      0.929      0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      3.51G      0.355     0.2371       1.06          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:49<00:00,  5.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:04<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.915      0.876      0.931      0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      3.55G     0.3454     0.2275      1.051          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:46<00:00,  5.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.898      0.898       0.93      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50       3.5G     0.3385     0.2227       1.04          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:50<00:00,  5.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.913      0.888      0.932      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      3.52G      0.333     0.2183      1.037          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895/895 [02:45<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:05<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.909      0.897      0.932      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 2.637 hours.\n",
      "Optimizer stripped from furniture_detection/yolov8s_furniture/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from furniture_detection/yolov8s_furniture/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating furniture_detection/yolov8s_furniture/weights/best.pt...\n",
      "Ultralytics 8.3.119 ðŸš€ Python-3.12.9 torch-2.7.0+cu126 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "Model summary (fused): 72 layers, 11,128,293 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:08<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.907      0.891      0.944      0.784\n",
      "                   Bed         70         71      0.971      0.887      0.944      0.777\n",
      "                 Chair         66         76      0.872      0.816      0.907      0.761\n",
      "              Cupboard        141        154      0.828      0.845      0.903      0.787\n",
      "            Nightstand         13         13      0.783          1      0.995      0.779\n",
      "             Sideboard         49         50      0.951        0.9       0.95      0.792\n",
      "                  Sofa        234        238      0.979      0.972      0.988      0.829\n",
      "                 Table        106        109      0.965      0.817      0.922      0.761\n",
      "Speed: 0.3ms preprocess, 2.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001B[1mfurniture_detection/yolov8s_furniture\u001B[0m\n",
      "\n",
      "Training completed in 9586.24 seconds (159.77 minutes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model on validation data...\n",
      "Ultralytics 8.3.119 ðŸš€ Python-3.12.9 torch-2.7.0+cu126 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "Model summary (fused): 72 layers, 11,128,293 parameters, 0 gradients, 28.5 GFLOPs\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access âœ… (ping: 1.6Â±0.1 ms, read: 20.5Â±12.3 MB/s, size: 59.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /mnt/e/IT/AI/JupyterProject/furniture-detection-1/valid/labels.cache... 652 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 652/652 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 63, len(boxes) = 711. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:07<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        652        711      0.911      0.889      0.944      0.783\n",
      "                   Bed         70         71      0.972      0.887      0.944      0.773\n",
      "                 Chair         66         76      0.875      0.816      0.908      0.764\n",
      "              Cupboard        141        154      0.833      0.838      0.903      0.786\n",
      "            Nightstand         13         13      0.786          1      0.995      0.779\n",
      "             Sideboard         49         50      0.956        0.9       0.95      0.792\n",
      "                  Sofa        234        238      0.979      0.969      0.988      0.827\n",
      "                 Table        106        109      0.974      0.817      0.922      0.761\n",
      "Speed: 0.5ms preprocess, 4.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001B[1mfurniture_detection/yolov8s_furniture\u001B[0m\n",
      "Validation mAP50: 0.9443\n",
      "Validation mAP50-95: 0.7834\n",
      "\n",
      "Exporting model to different formats...\n",
      "Exporting to ONNX...\n",
      "Ultralytics 8.3.119 ðŸš€ Python-3.12.9 torch-2.7.0+cu126 CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n",
      "\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from 'furniture_detection/yolov8s_furniture/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 11, 8400) (21.5 MB)\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim>=0.1.46', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
      "WARNING âš ï¸ Retry 1/2 failed: Command 'pip install --no-cache-dir \"onnx>=1.12.0\" \"onnxslim>=0.1.46\" \"onnxruntime-gpu\" ' returned non-zero exit status 127.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pip: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ Retry 2/2 failed: Command 'pip install --no-cache-dir \"onnx>=1.12.0\" \"onnxslim>=0.1.46\" \"onnxruntime-gpu\" ' returned non-zero exit status 127.\n",
      "WARNING âš ï¸ \u001B[31m\u001B[1mrequirements:\u001B[0m âŒ Command 'pip install --no-cache-dir \"onnx>=1.12.0\" \"onnxslim>=0.1.46\" \"onnxruntime-gpu\" ' returned non-zero exit status 127.\n",
      "ERROR âŒ \u001B[34m\u001B[1mONNX:\u001B[0m export failure 2.1s: No module named 'onnx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pip: not found\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnx'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 142\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;66;03m# 1. Export to ONNX format\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExporting to ONNX...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 142\u001B[0m onnx_path \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mexport(\u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monnx\u001B[39m\u001B[38;5;124m\"\u001B[39m, dynamic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, simplify\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mONNX model saved to: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00monnx_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;66;03m# 2. Export to TorchScript format\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/model.py:727\u001B[0m, in \u001B[0;36mModel.export\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    719\u001B[0m custom \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    720\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimgsz\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimgsz\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    721\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    724\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mverbose\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    725\u001B[0m }  \u001B[38;5;66;03m# method defaults\u001B[39;00m\n\u001B[1;32m    726\u001B[0m args \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moverrides, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcustom, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexport\u001B[39m\u001B[38;5;124m\"\u001B[39m}  \u001B[38;5;66;03m# highest priority args on the right\u001B[39;00m\n\u001B[0;32m--> 727\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Exporter(overrides\u001B[38;5;241m=\u001B[39margs, _callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks)(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/exporter.py:452\u001B[0m, in \u001B[0;36mExporter.__call__\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m    450\u001B[0m     f[\u001B[38;5;241m1\u001B[39m], _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexport_engine(dla\u001B[38;5;241m=\u001B[39mdla)\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m onnx:  \u001B[38;5;66;03m# ONNX\u001B[39;00m\n\u001B[0;32m--> 452\u001B[0m     f[\u001B[38;5;241m2\u001B[39m], _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexport_onnx()\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m xml:  \u001B[38;5;66;03m# OpenVINO\u001B[39;00m\n\u001B[1;32m    454\u001B[0m     f[\u001B[38;5;241m3\u001B[39m], _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexport_openvino()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/exporter.py:195\u001B[0m, in \u001B[0;36mtry_export.<locals>.outer_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    194\u001B[0m     LOGGER\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m export failure \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdt\u001B[38;5;241m.\u001B[39mt\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 195\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/exporter.py:190\u001B[0m, in \u001B[0;36mtry_export.<locals>.outer_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Profile() \u001B[38;5;28;01mas\u001B[39;00m dt:\n\u001B[0;32m--> 190\u001B[0m         f, model \u001B[38;5;241m=\u001B[39m inner_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    191\u001B[0m     LOGGER\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m export success âœ… \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdt\u001B[38;5;241m.\u001B[39mt\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms, saved as \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_size(f)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m MB)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f, model\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/exporter.py:553\u001B[0m, in \u001B[0;36mExporter.export_onnx\u001B[0;34m(self, prefix)\u001B[0m\n\u001B[1;32m    551\u001B[0m     requirements \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monnxslim>=0.1.46\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monnxruntime\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-gpu\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[1;32m    552\u001B[0m check_requirements(requirements)\n\u001B[0;32m--> 553\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m    555\u001B[0m opset_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mopset \u001B[38;5;129;01mor\u001B[39;00m get_latest_opset()\n\u001B[1;32m    556\u001B[0m LOGGER\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mprefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m starting export with onnx \u001B[39m\u001B[38;5;132;01m{\u001B[39;00monnx\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m opset \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mopset_version\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'onnx'"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "# YOLOv8 Furniture Detection Training\n",
    "# This notebook walks through the process of training and exporting a YOLOv8 model for furniture detection\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Check for GPU availability\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {device_count}\")\n",
    "    for i in range(device_count):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"GPU {i} memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Load Roboflow dataset (use your API key)\n",
    "rf = Roboflow(api_key=\"kSZm10tyRftk8dYF4iTM\")  # Replace with your actual API key\n",
    "project = rf.workspace(\"object-detection-paxjm\").project(\"furniture-detection-qiufc-czaes\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n",
    "dataset_path = dataset.location\n",
    "\n",
    "# Print dataset structure\n",
    "print(\"\\nDataset Information:\")\n",
    "with open(os.path.join(dataset_path, 'data.yaml'), 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "    print(f\"Classes: {data_config['names']}\")\n",
    "    print(f\"Number of classes: {data_config['nc']}\")\n",
    "\n",
    "# Verify train/val/test splits\n",
    "print(f\"Train images: {len(list(Path(data_config['train']).glob('*.jpg')))}\")\n",
    "print(f\"Validation images: {len(list(Path(data_config['val']).glob('*.jpg')))}\")\n",
    "if 'test' in data_config:\n",
    "    print(f\"Test images: {len(list(Path(data_config['test']).glob('*.jpg')))}\")\n",
    "\n",
    "# Define a function to plot training results\n",
    "def plot_results(results_file):\n",
    "    # Load results from the CSV file\n",
    "    from pandas import read_csv\n",
    "    results = read_csv(results_file)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # Plot metrics\n",
    "    ax[0, 0].plot(results['epoch'], results['train/box_loss'], label='train')\n",
    "    ax[0, 0].plot(results['epoch'], results['val/box_loss'], label='val')\n",
    "    ax[0, 0].set_title('Box Loss')\n",
    "    ax[0, 0].legend()\n",
    "\n",
    "    ax[0, 1].plot(results['epoch'], results['train/cls_loss'], label='train')\n",
    "    ax[0, 1].plot(results['epoch'], results['val/cls_loss'], label='val')\n",
    "    ax[0, 1].set_title('Class Loss')\n",
    "    ax[0, 1].legend()\n",
    "\n",
    "    ax[1, 0].plot(results['epoch'], results['train/dfl_loss'], label='train')\n",
    "    ax[1, 0].plot(results['epoch'], results['val/dfl_loss'], label='val')\n",
    "    ax[1, 0].set_title('DFL Loss')\n",
    "    ax[1, 0].legend()\n",
    "\n",
    "    ax[1, 1].plot(results['epoch'], results['metrics/precision(B)'], label='precision')\n",
    "    ax[1, 1].plot(results['epoch'], results['metrics/recall(B)'], label='recall')\n",
    "    ax[1, 1].plot(results['epoch'], results['metrics/mAP50(B)'], label='mAP50')\n",
    "    ax[1, 1].plot(results['epoch'], results['metrics/mAP50-95(B)'], label='mAP50-95')\n",
    "    ax[1, 1].set_title('Performance Metrics')\n",
    "    ax[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Model configuration\n",
    "# Choose model size from: n (nano), s (small), m (medium), l (large), x (xlarge)\n",
    "MODEL_SIZE = 's'  # adjust based on your GPU VRAM - medium is a good balance\n",
    "EPOCHS = 50 # 100\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 16  # adjust based on your GPU VRAM\n",
    "PATIENCE = 15  # for early stopping\n",
    "\n",
    "# Initialize model\n",
    "print(f\"\\nInitializing YOLOv8{MODEL_SIZE} model...\")\n",
    "model = YOLO(f'yolov8{MODEL_SIZE}.pt')  # Load pretrained model\n",
    "\n",
    "# Define training configuration\n",
    "training_args = {\n",
    "    'data': os.path.join(dataset_path, 'data.yaml'),\n",
    "    'epochs': EPOCHS,\n",
    "    'imgsz': IMG_SIZE,\n",
    "    'batch': BATCH_SIZE,\n",
    "    'patience': PATIENCE,\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "    'workers': 4,  # number of worker threads for data loading\n",
    "    'project': 'furniture_detection',\n",
    "    'name': f'yolov8{MODEL_SIZE}_furniture',\n",
    "    'exist_ok': True,  # overwrite existing project/name\n",
    "    'pretrained': True,  # use pretrained model\n",
    "    'optimizer': 'auto',  # optimizer (SGD, Adam, AdamW, etc.)\n",
    "    'lr0': 0.01,  # initial learning rate\n",
    "    'lrf': 0.01,  # final learning rate fraction\n",
    "    'momentum': 0.937,  # SGD momentum/Adam beta1\n",
    "    'weight_decay': 0.0005,  # optimizer weight decay\n",
    "    'warmup_epochs': 3.0,  # warmup epochs\n",
    "    'warmup_momentum': 0.8,  # warmup initial momentum\n",
    "    'warmup_bias_lr': 0.1,  # warmup initial bias lr\n",
    "    'seed': 0,  # deterministic seed\n",
    "    'deterministic': True,  # deterministic training\n",
    "    'save': True,  # save checkpoints\n",
    "    'save_period': -1,  # save checkpoint every x epochs (-1 to disable)\n",
    "    'verbose': True,  # verbose output\n",
    "}\n",
    "\n",
    "# Start training\n",
    "print(\"\\nStarting training...\")\n",
    "start_time = time.time()\n",
    "results = model.train(**training_args)\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "\n",
    "# Plot training results\n",
    "results_file = list(Path(f'furniture_detection/yolov8{MODEL_SIZE}_furniture').glob('results*.csv'))[0]\n",
    "plot_results(results_file)\n",
    "\n",
    "# Evaluate model on validation data\n",
    "print(\"\\nEvaluating model on validation data...\")\n",
    "val_results = model.val(data=os.path.join(dataset_path, 'data.yaml'))\n",
    "print(f\"Validation mAP50: {val_results.box.map50:.4f}\")\n",
    "print(f\"Validation mAP50-95: {val_results.box.map:.4f}\")\n",
    "\n",
    "# Export model to different formats\n",
    "print(\"\\nExporting model to different formats...\")\n",
    "\n",
    "# 1. Export to ONNX format\n",
    "print(\"Exporting to ONNX...\")\n",
    "onnx_path = model.export(format=\"onnx\", dynamic=True, simplify=True)\n",
    "print(f\"ONNX model saved to: {onnx_path}\")\n",
    "\n",
    "# 2. Export to TorchScript format\n",
    "print(\"Exporting to TorchScript...\")\n",
    "torchscript_path = model.export(format=\"torchscript\")\n",
    "print(f\"TorchScript model saved to: {torchscript_path}\")\n",
    "\n",
    "# 3. Export to CoreML format (for macOS/iOS deployment)\n",
    "try:\n",
    "    print(\"Exporting to CoreML...\")\n",
    "    coreml_path = model.export(format=\"coreml\")\n",
    "    print(f\"CoreML model saved to: {coreml_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"CoreML export failed: {e}\")\n",
    "\n",
    "# Optional: Test inference on a sample image\n",
    "print(\"\\nTesting inference on a sample image...\")\n",
    "sample_images = list(Path(data_config['val']).glob('*.jpg'))\n",
    "if sample_images:\n",
    "    test_img = str(sample_images[0])\n",
    "    print(f\"Running inference on {test_img}\")\n",
    "\n",
    "    # Perform detection\n",
    "    results = model(test_img)\n",
    "\n",
    "    # Plot results\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    ax.imshow(plt.imread(test_img))\n",
    "\n",
    "    # Get detections\n",
    "    boxes = results[0].boxes\n",
    "    for box in boxes:\n",
    "        # Get coordinates\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "\n",
    "        # Get confidence and class\n",
    "        conf = box.conf[0].item()\n",
    "        cls = int(box.cls[0].item())\n",
    "        label = f\"{data_config['names'][cls]} {conf:.2f}\"\n",
    "\n",
    "        # Plot bounding box\n",
    "        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add label\n",
    "        ax.text(x1, y1, label, bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "    plt.title(\"Sample Detection\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nDone! Your model has been trained and exported successfully.\")\n",
    "print(f\"Best model path: {model.best}\")\n",
    "\n",
    "# Final reminders and next steps\n",
    "print(\"\\nReminders for Django integration:\")\n",
    "print(\"1. Copy the exported ONNX model to your Django app's ml_models directory\")\n",
    "print(\"2. Update the model_loader.py file to point to the correct model file\")\n",
    "print(\"3. Test the API with sample images before deploying to production\")"
   ],
   "id": "96069a5b09f1885c"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"kSZm10tyRftk8dYF4iTM\")\n",
    "project = rf.workspace(\"object-detection-paxjm\").project(\"furniture-detection-qiufc-czaes\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T15:15:14.252790Z",
     "start_time": "2025-04-28T15:15:12.046994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Export to TorchScript format\n",
    "print(\"Exporting to TorchScript...\")\n",
    "torchscript_path = model.export(format=\"torchscript\")\n",
    "print(f\"TorchScript model saved to: {torchscript_path}\")"
   ],
   "id": "f5f978d79713e6da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to TorchScript...\n",
      "Ultralytics 8.3.119 ðŸš€ Python-3.12.9 torch-2.7.0+cu126 CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n",
      "\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from 'furniture_detection/yolov8s_furniture/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 11, 8400) (21.5 MB)\n",
      "\n",
      "\u001B[34m\u001B[1mTorchScript:\u001B[0m starting export with torch 2.7.0+cu126...\n",
      "\u001B[34m\u001B[1mTorchScript:\u001B[0m export success âœ… 1.8s, saved as 'furniture_detection/yolov8s_furniture/weights/best.torchscript' (42.9 MB)\n",
      "\n",
      "Export complete (2.2s)\n",
      "Results saved to \u001B[1m/mnt/e/IT/AI/JupyterProject/furniture_detection/yolov8s_furniture/weights\u001B[0m\n",
      "Predict:         yolo predict task=detect model=furniture_detection/yolov8s_furniture/weights/best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=furniture_detection/yolov8s_furniture/weights/best.torchscript imgsz=640 data=/mnt/e/IT/AI/JupyterProject/furniture-detection-1/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "TorchScript model saved to: furniture_detection/yolov8s_furniture/weights/best.torchscript\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T15:17:11.571029Z",
     "start_time": "2025-04-28T15:17:08.962104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Export to ONNX format\n",
    "print(\"Exporting to ONNX...\")\n",
    "onnx_path = model.export(format=\"onnx\", dynamic=True, simplify=True)\n",
    "print(f\"ONNX model saved to: {onnx_path}\")\n"
   ],
   "id": "38474c8f00725dab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to ONNX...\n",
      "Ultralytics 8.3.119 ðŸš€ Python-3.12.9 torch-2.7.0+cu126 CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n",
      "\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from 'furniture_detection/yolov8s_furniture/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 11, 8400) (21.5 MB)\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim>=0.1.46', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
      "WARNING âš ï¸ Retry 1/2 failed: Command 'pip install --no-cache-dir \"onnx>=1.12.0\" \"onnxslim>=0.1.46\" \"onnxruntime-gpu\" ' returned non-zero exit status 127.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pip: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ Retry 2/2 failed: Command 'pip install --no-cache-dir \"onnx>=1.12.0\" \"onnxslim>=0.1.46\" \"onnxruntime-gpu\" ' returned non-zero exit status 127.\n",
      "WARNING âš ï¸ \u001B[31m\u001B[1mrequirements:\u001B[0m âŒ Command 'pip install --no-cache-dir \"onnx>=1.12.0\" \"onnxslim>=0.1.46\" \"onnxruntime-gpu\" ' returned non-zero exit status 127.\n",
      "ERROR âŒ \u001B[34m\u001B[1mONNX:\u001B[0m export failure 2.1s: No module named 'onnx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pip: not found\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnx'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 1. Export to ONNX format\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExporting to ONNX...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m onnx_path \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mexport(\u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monnx\u001B[39m\u001B[38;5;124m\"\u001B[39m, dynamic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, simplify\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mONNX model saved to: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00monnx_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/model.py:727\u001B[0m, in \u001B[0;36mModel.export\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    719\u001B[0m custom \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    720\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimgsz\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimgsz\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    721\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    724\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mverbose\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    725\u001B[0m }  \u001B[38;5;66;03m# method defaults\u001B[39;00m\n\u001B[1;32m    726\u001B[0m args \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moverrides, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcustom, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexport\u001B[39m\u001B[38;5;124m\"\u001B[39m}  \u001B[38;5;66;03m# highest priority args on the right\u001B[39;00m\n\u001B[0;32m--> 727\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Exporter(overrides\u001B[38;5;241m=\u001B[39margs, _callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks)(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/exporter.py:452\u001B[0m, in \u001B[0;36mExporter.__call__\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m    450\u001B[0m     f[\u001B[38;5;241m1\u001B[39m], _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexport_engine(dla\u001B[38;5;241m=\u001B[39mdla)\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m onnx:  \u001B[38;5;66;03m# ONNX\u001B[39;00m\n\u001B[0;32m--> 452\u001B[0m     f[\u001B[38;5;241m2\u001B[39m], _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexport_onnx()\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m xml:  \u001B[38;5;66;03m# OpenVINO\u001B[39;00m\n\u001B[1;32m    454\u001B[0m     f[\u001B[38;5;241m3\u001B[39m], _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexport_openvino()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/exporter.py:195\u001B[0m, in \u001B[0;36mtry_export.<locals>.outer_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    194\u001B[0m     LOGGER\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m export failure \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdt\u001B[38;5;241m.\u001B[39mt\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 195\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/exporter.py:190\u001B[0m, in \u001B[0;36mtry_export.<locals>.outer_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Profile() \u001B[38;5;28;01mas\u001B[39;00m dt:\n\u001B[0;32m--> 190\u001B[0m         f, model \u001B[38;5;241m=\u001B[39m inner_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    191\u001B[0m     LOGGER\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m export success âœ… \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdt\u001B[38;5;241m.\u001B[39mt\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms, saved as \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_size(f)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m MB)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f, model\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/ultralytics/engine/exporter.py:553\u001B[0m, in \u001B[0;36mExporter.export_onnx\u001B[0;34m(self, prefix)\u001B[0m\n\u001B[1;32m    551\u001B[0m     requirements \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monnxslim>=0.1.46\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monnxruntime\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-gpu\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[1;32m    552\u001B[0m check_requirements(requirements)\n\u001B[0;32m--> 553\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m    555\u001B[0m opset_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mopset \u001B[38;5;129;01mor\u001B[39;00m get_latest_opset()\n\u001B[1;32m    556\u001B[0m LOGGER\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mprefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m starting export with onnx \u001B[39m\u001B[38;5;132;01m{\u001B[39;00monnx\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m opset \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mopset_version\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'onnx'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T15:37:56.313942Z",
     "start_time": "2025-04-28T15:37:56.152602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "# Perform detection\n",
    "results = model(test_img)\n",
    "\n",
    "# Your results is a list -> get the first item\n",
    "result = results[0]\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(test_img)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot image\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.imshow(img)\n",
    "\n",
    "# Now get boxes from result\n",
    "boxes = result.boxes\n",
    "\n",
    "for box in boxes:\n",
    "    # Get coordinates\n",
    "    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "\n",
    "    # Get confidence and class\n",
    "    conf = box.conf[0].cpu().item()\n",
    "    cls = int(box.cls[0].cpu().item())\n",
    "    label = f\"{data_config['names'][cls]} {conf:.2f}\"\n",
    "\n",
    "    # Draw bounding box\n",
    "    rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                              linewidth=2, edgecolor='red', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Draw label\n",
    "    ax.text(x1, y1, label, fontsize=10, color='black',\n",
    "            bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "plt.title(\"Sample Detection\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "aa6877618ef9286a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/e/IT/AI/JupyterProject/rustic_153.jpg: 640x640 1 Bed, 1 Nightstand, 93.9ms\n",
      "Speed: 4.2ms preprocess, 93.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
